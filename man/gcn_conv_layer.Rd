% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/layer-gcn.R
\name{gcn_conv_layer}
\alias{gcn_conv_layer}
\title{GCN Convolutional Layer (Kipf & Welling 2016)}
\usage{
gcn_conv_layer(in_features, out_features, bias = TRUE, normalize = TRUE)
}
\arguments{
\item{in_features}{Integer. Number of input features per node}

\item{out_features}{Integer. Number of output features per node}

\item{bias}{Logical. Add learnable bias. Default: TRUE}

\item{normalize}{Logical. Whether to add self-loops and compute symmetric normalization
on-the-fly. Default: TRUE}

\item{x}{Tensor \verb{n_nodes x in_features}. Node feature matrix}

\item{adj}{Tensor \verb{n_nodes x n_nodes}. Adjacency matrix defining graph structure.
Can be binary (0/1) or weighted. If \code{edge_weight} is provided, \code{adj}
should be binary and weights will be applied from \code{edge_weight}}
}
\value{
Tensor \verb{n_nodes x out_features}. Transformed node features
}
\description{
Implements the basic GCN layer from Kipf & Welling (2016):
\deqn{H^{(k)} = \sigma(\tilde{A} H^{(k-1)} W + b)}
}
\details{
Where \eqn{\tilde{A} = \tilde{D}^{-1/2}(A + I)\tilde{D}^{-1/2}} is the symmetrically normalized adjacency
matrix with self-loops, and \eqn{\tilde{D}} is the degree matrix of \eqn{A + I}.

This is the standard GCN layer that uses:
\itemize{
\item Single weight matrix \eqn{W}
\item Symmetric normalization with self-loops
\item Optional on-the-fly normalization
}

When \code{normalize = TRUE} (default), the layer computes \eqn{\tilde{A}} on-the-fly from
the input adjacency matrix by adding self-loops and applying symmetric normalization.
When \code{normalize = FALSE}, you must pass in a pre-normalized adjacency matrix.

Parameters:
\itemize{
\item \eqn{W}: \verb{in_features x out_features} learnable weight matrix
\item \eqn{b}: \code{out_features} learnable bias term (optional)
}
}
\section{Forward pass}{

}

\references{
Kipf, T. N., & Welling, M. (2016). Semi-supervised classification with
graph convolutional networks. arXiv preprint arXiv:1609.02907. \url{doi:10.48550/arXiv.1609.02907}
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-gcn.R
\name{gcn_conv_model}
\alias{gcn_conv_model}
\title{Multi-layer GCN Model}
\usage{
gcn_conv_model(
  in_features,
  hidden_dims,
  out_features,
  activation = nnf_relu,
  out_activation = NULL,
  dropout = 0,
  normalize = TRUE
)
}
\arguments{
\item{in_features}{Integer. Number of input features per node}

\item{hidden_dims}{Integer vector. Dimensions of hidden layers (length = L)}

\item{out_features}{Integer. Number of output features (typically 1 for regression)}

\item{activation}{Function. Activation for hidden layers. Default: nnf_relu}

\item{dropout}{Numeric. Dropout rate (0-1) applied after each hidden layer. Default: 0}

\item{normalize}{Logical. Whether to add self-loops and apply symmetric normalization.
Default: TRUE}

\item{output_activation}{Function or NULL. Activation for output layer. Default: NULL}

\item{x}{Tensor \verb{n_nodes x in_features}. Node feature matrix}

\item{adj}{Tensor \verb{n_nodes x n_nodes}. Binary adjacency matrix (0/1) defining graph structure.
When \code{normalize = TRUE}, self-loops are added and symmetric normalization is applied
automatically}

\item{edge_weight}{Tensor \verb{n_nodes x n_nodes} or NULL. Optional edge weights to
apply to the adjacency structure. If NULL, treats all edges as having weight 1.
Passed through to all layers. Default: NULL}
}
\value{
Tensor \verb{n_nodes x out_features}. Final predictions
}
\description{
Stacks multiple GCN layers to create a deep graph convolutional network.
}
\details{
Architecture:
\itemize{
\item L hidden GCN layers with configurable activation
\item 1 output GCN layer with optional output activation
\item Total layers = length(hidden_dims) + 1
}

For example, hidden_dims = c(56, 56) creates:
\itemize{
\item Layer 1: in_features → 56 (activation)
\item Layer 2: 56 → 56 (activation)
\item Layer 3: 56 → out_features (output_activation)
}

Uses \code{gcn_conv_layer} which automatically handles adding self-loops and symmetric
normalization when \code{normalize = TRUE}.
}
\section{Forward pass}{

}

\examples{
\dontrun{
# Binary classification with sigmoid
model <- gcn_model(14, c(56, 56), 1, output_activation = nnf_sigmoid)

# Multi-class with softmax
model <- gcn_model(
  14,
  c(32, 32),
  10,
  output_activation = function(x) nnf_softmax(x, dim = -1)
)

# Regression (no output activation)
model <- gcn_model(14, c(64, 64), 1)

# With dropout and tanh activation
model <- gcn_model(14, c(56, 56), 1,
                   activation = nnf_tanh,
                   dropout = 0.5)
}
}

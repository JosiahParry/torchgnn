% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-sage.R
\name{sage_model}
\alias{sage_model}
\title{Multi-layer GraphSAGE Model (Hamilton et al. 2017)}
\usage{
sage_model(
  in_features,
  hidden_dims,
  out_features,
  aggregator = MeanAggregator(),
  activation = nnf_relu,
  out_activation = NULL,
  dropout = 0,
  concat = TRUE
)
}
\arguments{
\item{in_features}{Integer. Number of input features per node}

\item{hidden_dims}{Integer vector. Dimensions of hidden layers (length = L)}

\item{out_features}{Integer. Number of output features (typically 1 for regression)}

\item{aggregator}{Aggregator S7 object. Aggregation function for all layers.
Default: \code{MeanAggregator()}}

\item{activation}{Function. Activation for hidden layers. Default: nnf_relu}

\item{out_activation}{Function or NULL. Activation for output layer. Default: NULL}

\item{dropout}{Numeric. Dropout rate (0-1) applied after each hidden layer. Default: 0}

\item{concat}{Logical. If TRUE, concatenates self and neighbor features. If FALSE,
adds them. Default: TRUE}

\item{x}{Tensor \verb{n_nodes x in_features}. Node feature matrix (dense or sparse)}

\item{adj}{Sparse torch tensor \verb{n_nodes x n_nodes}. Adjacency matrix defining graph
structure. Must be a sparse COO tensor.}
}
\value{
Tensor \verb{n_nodes x out_features}. Final predictions
}
\description{
Stacks multiple GraphSAGE layers with configurable aggregation functions.
}
\details{
Architecture:
\itemize{
\item L hidden SAGE layers with configurable activation
\item 1 output SAGE layer with optional output activation
\item Total layers = length(hidden_dims) + 1
}

Each layer aggregates neighbor features using the specified aggregator, then
combines with self features via concatenation or addition.
}
\section{Forward pass}{

}

\examples{
\dontrun{
# Binary classification with sigmoid and mean aggregation
model <- sage_model(14, c(56, 56), 1, output_activation = nnf_sigmoid)

# Multi-class with softmax and max aggregation
model <- sage_model(
  14,
  c(32, 32),
  10,
  aggregator = MaxAggregator(),
  output_activation = function(x) nnf_softmax(x, dim = -1)
)

# Regression with sum aggregation
model <- sage_model(14, c(64, 64), 1, aggregator = SumAggregator())

# With dropout and custom activation
model <- sage_model(
  14,
  c(56, 56),
  1,
  activation = nnf_tanh,
  dropout = 0.5
)
}

}
\references{
Hamilton, W., Ying, Z., & Leskovec, J. (2017). Inductive representation learning
on large graphs. Advances in Neural Information Processing Systems, 30.
\url{doi:10.48550/arXiv.1706.02216}
}

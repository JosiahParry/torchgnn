[{"path":"https://josiahparry.github.io/torchgnn/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Josiah Parry. Author, maintainer.","code":""},{"path":"https://josiahparry.github.io/torchgnn/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Parry J (2025). torchgnn: Graph Neural Network Extensions 'torch'. R package version 0.0.0.9000, https://josiahparry.github.io/torchgnn/.","code":"@Manual{,   title = {torchgnn: Graph Neural Network Extensions for `torch`},   author = {Josiah Parry},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://josiahparry.github.io/torchgnn/}, }"},{"path":"https://josiahparry.github.io/torchgnn/index.html","id":"torchgnn","dir":"","previous_headings":"","what":"Graph Neural Network Extensions for `torch`","title":"Graph Neural Network Extensions for `torch`","text":"Graph Neural Networks {torch} R.","code":""},{"path":"https://josiahparry.github.io/torchgnn/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Graph Neural Network Extensions for `torch`","text":"Install development version package using","code":"pak::pak(\"josiahparry/torchgnn\")"},{"path":"https://josiahparry.github.io/torchgnn/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Graph Neural Network Extensions for `torch`","text":"Use gcn_model() create high level model: create individual layers using gcn_layer():","code":"library(torchgnn)  gcn_model(   in_features = 14,   hidden_dims = c(56, 56),   out_features = 1,   output_activation = torch::nnf_sigmoid ) An `nn_module` containing 8,065 parameters.  ── Modules ───────────────────────────────────────────────────────────────────── • layers: <nn_module_list> #8,065 parameters gcn_layer(10, 1) An `nn_module` containing 21 parameters.  ── Modules ───────────────────────────────────────────────────────────────────── • theta: <nn_linear> #10 parameters • phi: <nn_linear> #10 parameters  ── Parameters ────────────────────────────────────────────────────────────────── • psi: Float [1:1, 1:1]"},{"path":"https://josiahparry.github.io/torchgnn/reference/adj_from_edgelist.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Sparse Adjacency Matrix from Edge List — adj_from_edgelist","title":"Create Sparse Adjacency Matrix from Edge List — adj_from_edgelist","text":"Create Sparse Adjacency Matrix Edge List","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/adj_from_edgelist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Sparse Adjacency Matrix from Edge List — adj_from_edgelist","text":"","code":"adj_from_edgelist(from, to, weight = NULL, n = NULL, symmetric = TRUE)"},{"path":"https://josiahparry.github.io/torchgnn/reference/adj_from_edgelist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Sparse Adjacency Matrix from Edge List — adj_from_edgelist","text":"Integer character vector source nodes Integer character vector target nodes weight Numeric vector edge weights n Number nodes symmetric Make adjacency symmetric","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/adj_from_edgelist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Sparse Adjacency Matrix from Edge List — adj_from_edgelist","text":"Sparse COO tensor attributes node_ids id_map","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/adjacency.html","id":null,"dir":"Reference","previous_headings":"","what":"Add self-loops to a graph — gcn_normalize","title":"Add self-loops to a graph — gcn_normalize","text":"Add self-loops graph","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/adjacency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add self-loops to a graph — gcn_normalize","text":"","code":"gcn_normalize(adj)  adj_row_normalize(adj)  add_graph_self_loops(adj)"},{"path":"https://josiahparry.github.io/torchgnn/reference/adjacency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add self-loops to a graph — gcn_normalize","text":"adj sparse COO tensor adjacency matrix. Can weighted.","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"GCN Convolutional Layer (Kipf & Welling 2016) — gcn_conv_layer","title":"GCN Convolutional Layer (Kipf & Welling 2016) — gcn_conv_layer","text":"Implements basic GCN layer Kipf & Welling (2016): $$H^{(k)} = \\sigma(\\tilde{} H^{(k-1)} W + b)$$","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GCN Convolutional Layer (Kipf & Welling 2016) — gcn_conv_layer","text":"","code":"gcn_conv_layer(in_features, out_features, bias = TRUE, normalize = TRUE)"},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GCN Convolutional Layer (Kipf & Welling 2016) — gcn_conv_layer","text":"in_features Integer. Number input features per node out_features Integer. Number output features per node bias Logical. Add learnable bias. Default: TRUE normalize Logical. Whether add self-loops compute symmetric normalization --fly. Default: TRUE x Tensor n_nodes x in_features. Node feature matrix adj Tensor n_nodes x n_nodes. Adjacency matrix defining graph structure. Can binary (0/1) weighted. edge_weight provided, adj binary weights applied edge_weight","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GCN Convolutional Layer (Kipf & Welling 2016) — gcn_conv_layer","text":"Tensor n_nodes x out_features. Transformed node features","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_layer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"GCN Convolutional Layer (Kipf & Welling 2016) — gcn_conv_layer","text":"\\(\\tilde{} = \\tilde{D}^{-1/2}(+ )\\tilde{D}^{-1/2}\\) symmetrically normalized adjacency matrix self-loops, \\(\\tilde{D}\\) degree matrix \\(+ \\). standard GCN layer uses: Single weight matrix \\(W\\) Symmetric normalization self-loops Optional --fly normalization normalize = TRUE (default), layer computes \\(\\tilde{}\\) --fly input adjacency matrix adding self-loops applying symmetric normalization. normalize = FALSE, must pass pre-normalized adjacency matrix. Parameters: \\(W\\): in_features x out_features learnable weight matrix \\(b\\): out_features learnable bias term (optional)","code":""},{"path":[]},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_layer.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"GCN Convolutional Layer (Kipf & Welling 2016) — gcn_conv_layer","text":"Kipf, T. N., & Welling, M. (2016). Semi-supervised classification graph convolutional networks. arXiv preprint arXiv:1609.02907. doi:10.48550/arXiv.1609.02907","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-layer GCN Model — gcn_conv_model","title":"Multi-layer GCN Model — gcn_conv_model","text":"Stacks multiple GCN layers create deep graph convolutional network.","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-layer GCN Model — gcn_conv_model","text":"","code":"gcn_conv_model(   in_features,   hidden_dims,   out_features,   activation = nnf_relu,   out_activation = NULL,   dropout = 0,   normalize = TRUE )"},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-layer GCN Model — gcn_conv_model","text":"in_features Integer. Number input features per node hidden_dims Integer vector. Dimensions hidden layers (length = L) out_features Integer. Number output features (typically 1 regression) activation Function. Activation hidden layers. Default: nnf_relu dropout Numeric. Dropout rate (0-1) applied hidden layer. Default: 0 normalize Logical. Whether add self-loops apply symmetric normalization. Default: TRUE output_activation Function NULL. Activation output layer. Default: NULL x Tensor n_nodes x in_features. Node feature matrix adj Tensor n_nodes x n_nodes. Binary adjacency matrix (0/1) defining graph structure. normalize = TRUE, self-loops added symmetric normalization applied automatically edge_weight Tensor n_nodes x n_nodes NULL. Optional edge weights apply adjacency structure. NULL, treats edges weight 1. Passed layers. Default: NULL","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multi-layer GCN Model — gcn_conv_model","text":"Tensor n_nodes x out_features. Final predictions","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multi-layer GCN Model — gcn_conv_model","text":"Architecture: L hidden GCN layers configurable activation 1 output GCN layer optional output activation Total layers = length(hidden_dims) + 1 example, hidden_dims = c(56, 56) creates: Layer 1: in_features → 56 (activation) Layer 2: 56 → 56 (activation) Layer 3: 56 → out_features (output_activation) Uses gcn_conv_layer automatically handles adding self-loops symmetric normalization normalize = TRUE.","code":""},{"path":[]},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_conv_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multi-layer GCN Model — gcn_conv_model","text":"","code":"if (FALSE) { # \\dontrun{ # Binary classification with sigmoid model <- gcn_model(14, c(56, 56), 1, output_activation = nnf_sigmoid)  # Multi-class with softmax model <- gcn_model(   14,   c(32, 32),   10,   output_activation = function(x) nnf_softmax(x, dim = -1) )  # Regression (no output activation) model <- gcn_model(14, c(64, 64), 1)  # With dropout and tanh activation model <- gcn_model(14, c(56, 56), 1,                    activation = nnf_tanh,                    dropout = 0.5) } # }"},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_general_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized GCN Layer (Hamilton 2020) — gcn_general_layer","title":"Generalized GCN Layer (Hamilton 2020) — gcn_general_layer","text":"Implements single Graph Convolutional Network (GCN) layer following Hamilton 2020: $$\\mathbf{H}^{(k)} = \\sigma\\left(\\mathbf{}\\mathbf{H}^{(k-1)}\\mathbf{W}^{(k)}_{\\text{neigh}} + \\mathbf{H}^{(k-1)}\\mathbf{W}^{(k)}_{\\text{self}}\\right)$$ can also written (Guo et al. 2025): $$\\mathbf{X}^{(l)} = \\sigma\\left(\\mathbf{D}^{-1}\\mathbf{}\\mathbf{X}^{(l-1)}\\boldsymbol{\\Theta}^{(l)} + \\mathbf{X}^{(l-1)}\\boldsymbol{\\Phi}^{(l)} + \\boldsymbol{\\Psi}^{(l)}\\right)$$ layer combines: Neighbor aggregation: \\(D^{-1}AX^{(l-1)}\\Theta^{(l)}\\) Self transformation: \\(X^{(l-1)}\\Phi^{(l)}\\) focal node transformation Global bias: \\(\\Psi^{(l)}\\) additive bias term Parameters: \\(\\Theta\\) (theta): in_features x out_features transforms aggregated neighbor features \\(\\Phi\\) (phi): in_features x out_features transforms node's features \\(\\Psi\\) (psi): out_features global bias term (shared across nodes)","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_general_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized GCN Layer (Hamilton 2020) — gcn_general_layer","text":"","code":"gcn_general_layer(in_features, out_features, bias = TRUE, normalize = FALSE)"},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_general_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized GCN Layer (Hamilton 2020) — gcn_general_layer","text":"in_features Integer. Number input features per node out_features Integer. Number output features per node bias Logical. Add learnable bias term (\\(\\Psi\\)). Default: TRUE x Tensor n_nodes x in_features. Node feature matrix adj Tensor n_nodes x n_nodes. Adjacency matrix. Expected row-normalized \\(D^{-1}\\) \\(D\\) degree matrix. Can binary weighted. layer perform normalization internally","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_general_layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized GCN Layer (Hamilton 2020) — gcn_general_layer","text":"Tensor n_nodes x out_features. Transformed node features (activation)","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_general_layer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized GCN Layer (Hamilton 2020) — gcn_general_layer","text":"adjacency matrix expected row-normalized \\(D^{-1}\\) \\(D\\) degree matrix. layer perform normalization internally.","code":""},{"path":[]},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_general_layer.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized GCN Layer (Hamilton 2020) — gcn_general_layer","text":"Hamilton, W. L. (2020). Graph Representation Learning. Synthesis Lectures Artificial Intelligence Machine Learning. Springer International Publishing. doi:10.1007/978-3-031-01588-5 Guo, H., Wang, H., Zhu, D., Wu, L., Fotheringham, . S., & Liu, Y. (2025). RegionGCN: Spatial-Heterogeneity-Aware Graph Convolutional Networks. Annals American Association Geographers, 1–17. doi:10.1080/24694452.2025.2558661","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_general_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-layer Generalized GCN Model (Hamilton 2020) — gcn_general_model","title":"Multi-layer Generalized GCN Model (Hamilton 2020) — gcn_general_model","text":"Stacks multiple generalized GCN layers neighbor/self weight separation. Optional row-normalization applied internally normalize = TRUE.","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/gcn_general_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-layer Generalized GCN Model (Hamilton 2020) — gcn_general_model","text":"","code":"gcn_general_model(   in_features,   hidden_dims,   out_features,   activation = nnf_relu,   out_activation = NULL,   dropout = 0,   normalize = TRUE )"},{"path":"https://josiahparry.github.io/torchgnn/reference/graph_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Train/Validation/Test Split for Graph Data — graph_split","title":"Create Train/Validation/Test Split for Graph Data — graph_split","text":"Creates splits graph neural networks following rsample's structure. Unlike traditional ML, GCNs use full graph training compute loss labeled (training) nodes.","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/graph_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Train/Validation/Test Split for Graph Data — graph_split","text":"","code":"graph_split(data, prop = c(0.6, 0.2, 0.2), seed = NULL)"},{"path":"https://josiahparry.github.io/torchgnn/reference/graph_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Train/Validation/Test Split for Graph Data — graph_split","text":"data Data frame adjacency matrix. full dataset split. prop Numeric vector length 2 3. Proportions splits. Length 2: c(train, test) - creates train/test split Length 3: c(train, val, test) - creates train/val/test split Must sum 1.0. Default: c(0.6, 0.2, 0.2) seed Integer NULL. Random seed reproducibility. Default: NULL","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/graph_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Train/Validation/Test Split for Graph Data — graph_split","text":"graph_split object (list) containing: data: Original data train_id: Integer vector training indices val_id: Integer vector validation indices (NULL length(prop) == 2) test_id: Integer vector test indices","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/graph_split.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Train/Validation/Test Split for Graph Data — graph_split","text":"proportions must sum 1.0. function creates non-overlapping splits row belongs exactly one split. GCN training, use: Full X A_sparse forward passes IDs select predictions use loss computation","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/graph_split.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Train/Validation/Test Split for Graph Data — graph_split","text":"","code":"if (FALSE) { # \\dontrun{ # Standard 60/20/20 split split <- graph_split(A_sparse, seed = 42)  # Custom split (70/15/15) split <- graph_split(A_sparse, prop = c(0.7, 0.15, 0.15))  # Two-way split (80/20 train/test) split <- graph_split(A_sparse, prop = c(0.8, 0.2))  # Use in training predictions <- model(X, A_sparse) train_loss <- nnf_mse_loss(predictions[split$train_id], y[split$train_id]) } # }"},{"path":"https://josiahparry.github.io/torchgnn/reference/nodes_to_tensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Node Features to Tensor — nodes_to_tensor","title":"Convert Node Features to Tensor — nodes_to_tensor","text":"Convert Node Features Tensor","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/nodes_to_tensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Node Features to Tensor — nodes_to_tensor","text":"","code":"nodes_to_tensor(nodes, adj = NULL, node_id = NULL)"},{"path":"https://josiahparry.github.io/torchgnn/reference/nodes_to_tensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Node Features to Tensor — nodes_to_tensor","text":"nodes Dataframe node features adj Adjacency matrix id_map attribute node_id Column name node IDs","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/nodes_to_tensor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Node Features to Tensor — nodes_to_tensor","text":"Dense tensor shape [n_nodes, n_features]","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/regconv_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Regional GCN Convolutional Layer (Guo et al. 2025) — regconv_layer","title":"Regional GCN Convolutional Layer (Guo et al. 2025) — regconv_layer","text":"Implements Regional Graph Convolutional Network (RegConv) layer Guo et al. (2025): $$\\mathbf{X}^{(l)} = \\sigma\\left(\\left(\\mathbf{D}^{-1}\\mathbf{}\\mathbf{X}^{(l-1)}\\boldsymbol{\\Theta}^{(l)} + \\mathbf{X}^{(l-1)}\\boldsymbol{\\Phi}^{(l)}\\right)\\boldsymbol{\\Omega}_{reg}^{(l)} + \\boldsymbol{\\Psi}_{reg}^{(l)}\\right)$$ layer extends standard GCN layer introducing region-specific parameters handle spatial heterogeneity (spatial regimes). computation two stages: Base GCN transformation: \\(\\mathbf{D}^{-1}\\mathbf{}\\mathbf{X}^{(l-1)}\\boldsymbol{\\Theta}^{(l)} + \\mathbf{X}^{(l-1)}\\boldsymbol{\\Phi}^{(l)}\\) Region-specific modulation: Element-wise multiplication \\(\\boldsymbol{\\Omega}_{reg}\\) addition \\(\\boldsymbol{\\Psi}_{reg}\\) Parameters: \\(\\Theta\\) (theta): in_features x out_features transforms aggregated neighbor features (global) \\(\\Phi\\) (phi): in_features x out_features transforms node's features (global) \\(\\Omega_{reg}\\) (omega_reg): n_regions x out_features region-specific weight modulation \\(\\Psi_{reg}\\) (psi_reg): n_regions x out_features region-specific bias terms","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/regconv_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regional GCN Convolutional Layer (Guo et al. 2025) — regconv_layer","text":"","code":"regconv_layer(in_features, out_features, n_regions)"},{"path":"https://josiahparry.github.io/torchgnn/reference/regconv_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regional GCN Convolutional Layer (Guo et al. 2025) — regconv_layer","text":"in_features Integer. Number input features per node out_features Integer. Number output features per node n_regions Integer. Number spatial regions/regimes x Tensor n_nodes x in_features. Node feature matrix adj Tensor n_nodes x n_nodes. Adjacency matrix. Expected row-normalized \\(D^{-1}\\) \\(D\\) degree matrix. Can binary weighted region_assignments Tensor n_nodes. Integer vector values 1:n_regions, indicating region node belongs . Multiple nodes can belong region edge_weight Tensor n_nodes x n_nodes NULL. Optional edge weights apply adjacency matrix. NULL, uses values adj. Default: NULL","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/regconv_layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regional GCN Convolutional Layer (Guo et al. 2025) — regconv_layer","text":"Tensor n_nodes x out_features. Transformed node features (activation)","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/regconv_layer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regional GCN Convolutional Layer (Guo et al. 2025) — regconv_layer","text":"RegConv layer designed two-stage training: Stage 1: Train global GCN learn \\(\\Theta\\) \\(\\Phi\\), freeze parameters. Stage 2: Initialize \\(\\Omega_{reg}\\) 1s train region-specific parameters (\\(\\Omega_{reg}\\), \\(\\Psi_{reg}\\)) keeping \\(\\Theta\\) \\(\\Phi\\) fixed. region-specific parameters allow model adjust predictions differently across spatial regimes, enabling model capture spatial heterogeneity.","code":""},{"path":[]},{"path":"https://josiahparry.github.io/torchgnn/reference/regconv_layer.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regional GCN Convolutional Layer (Guo et al. 2025) — regconv_layer","text":"Guo, H., Wang, H., Zhu, D., Wu, L., Fotheringham, . S., & Liu, Y. (2025). RegionGCN: Spatial-Heterogeneity-Aware Graph Convolutional Networks. Annals American Association Geographers, 1–17. doi:10.1080/24694452.2025.2558661","code":""},{"path":"https://josiahparry.github.io/torchgnn/reference/torchgnn-package.html","id":null,"dir":"Reference","previous_headings":"","what":"torchgnn: Graph Neural Network Extensions for `torch` — torchgnn-package","title":"torchgnn: Graph Neural Network Extensions for `torch` — torchgnn-package","text":"package (one paragraph).","code":""},{"path":[]},{"path":"https://josiahparry.github.io/torchgnn/reference/torchgnn-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"torchgnn: Graph Neural Network Extensions for `torch` — torchgnn-package","text":"Maintainer: Josiah Parry josiah.parry@gmail.com (ORCID)","code":""}]
